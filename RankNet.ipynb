{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, Input, Subtract\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_excel\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/joshua/Desktop/作品集整理/LTR/txc_data2\"\n",
    "dirs = os.listdir( path )   \n",
    "all_data = pd.DataFrame([])\n",
    "for file in dirs:\n",
    "   file = \"/Users/joshua/Desktop/作品集整理/LTR/txc_data2/\"+file\n",
    "   raw_data = read_excel(file, header=0, parse_dates=[0], squeeze=True, index_col = False,skiprows = [0])\n",
    "   raw_data = raw_data.iloc[1:,:]#拿掉spec row\n",
    "   #還不知道要drops8哪些columns\n",
    "   all_data = all_data.append(raw_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 篩選資料\n",
    "# 因商業關係，特徵值用 feature no. 代替\n",
    "pass_data = all_data[[ 'feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6', 'feature7', 'feature8', 'feature9', 'feature10', 'feature11']]\n",
    "pass_data = pass_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(pass_data.columns.values) #23767 #11 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料篩選\n",
    "pass_data = pass_data.loc[pass_data['feature10'] != \"DLD Dead\"]#23737\n",
    "pass_data = pass_data.loc[pass_data['feature11'] <180]#21846\n",
    "pass_data = pass_data.loc[abs(pass_data['feature1']-686) <= 5]#21755\n",
    "pass_data = pass_data.loc[abs(pass_data['feature2']-535) <= 5]#21431\n",
    "pass_data = pass_data.loc[abs(pass_data['feature3']-439) <= 5]#21428\n",
    "pass_data = pass_data.loc[abs(pass_data['feature4']-389) <= 5]#21425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 型態 float --> np.float\n",
    "pass_data['feature11'] = pass_data['feature11'].astype(float)\n",
    "pass_data['feature3'] = pass_data['feature3'].astype(float)\n",
    "pass_data['feature4'] = pass_data['feature4'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可嘗試不同的normalization\n",
    "def normalize(x, y, f):\n",
    "    spec_value = [686,535,439,389,52, 0]\n",
    "    y_nor = y-np.mean(y) # 平移至0附近 y.mean=74.120064\n",
    "    x_nor = np.copy(x)\n",
    "    count = 0\n",
    "    for s in spec_value:\n",
    "        x_nor[:, count] -= s\n",
    "        count+=1\n",
    "    if(f==7):\n",
    "        x_nor[:, 6] = x_nor[:, 6]/x_nor[:, 6].max(axis=0)  \n",
    "    #X座標, Y座標\n",
    "    if(f==8):\n",
    "        x_nor[:, 6:7] = x_nor[:, 6:7]/x_nor[:, 6:7].max(axis=0)   \n",
    "    #X座標, Y座標, 半徑\n",
    "    if(f==9):\n",
    "        x_nor[:, 6:8] = x_nor[:, 6:8]/x_nor[:, 6:8].max(axis=0)\n",
    "    return x_nor, y_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnum=8\n",
    "rs = 7\n",
    "\n",
    "if(fnum==6):\n",
    "    data = pass_data[['feature11', 'feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6']]\n",
    "if(fnum==7):\n",
    "    data = pass_data[['feature11', 'feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6', 'feature9']]\n",
    "if(fnum==8):\n",
    "    data = pass_data[['feature11', 'feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6','feature7', 'feature8']]\n",
    "if(fnum==9):\n",
    "    data = pass_data[['feature11', 'feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6','feature7', 'feature8', 'feature9']]# shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---x: features(物理測量)---\n",
    "x = data.drop(['feature11'],axis = 1)\n",
    "x = np.asarray(x,dtype=np.float32)\n",
    "#%%\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=rs)\n",
    "x_test_nor, y_test_nor = normalize(x_test, y_test, x.shape[1])\n",
    "x_train_nor, y_train_nor = normalize(x_train, y_train, x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['feature11'][:]\n",
    "y = np.asarray(y,dtype=np.float32)\n",
    "y = y.reshape(len(y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%get sample function\n",
    "def randomsample(x):\n",
    "    pair_num = 100000\n",
    "    a = np.asarray([np.random.randint(0,x.shape[0]) for _ in range(pair_num*2)])\n",
    "    first_pair = np.zeros((pair_num,x.shape[1]))\n",
    "    sec_pair = np.zeros((pair_num,x.shape[1]))\n",
    "    label = np.zeros((pair_num,1))\n",
    "    for i in range(pair_num):\n",
    "        first_pair[i,:] = x_train_nor[a[i*2]]\n",
    "        sec_pair[i,:] = x_train_nor[a[i*2+1]]\n",
    "        if (y_train_nor[a[i*2]]<=y_train_nor[a[i*2+1]]):\n",
    "            label[i] = 1\n",
    "        else:\n",
    "            label[i] = 0\n",
    "    return first_pair, sec_pair, label\n",
    "\n",
    "def randomtestsample(x_test):\n",
    "    pair_num = 10000\n",
    "    a = np.asarray([np.random.randint(0,x_test.shape[0]) for _ in range(pair_num*2)])\n",
    "    first_pair = np.zeros((pair_num,x_test.shape[1]))\n",
    "    sec_pair = np.zeros((pair_num,x_test.shape[1]))\n",
    "    label = np.reshape(np.zeros((pair_num,1)),(pair_num,1))\n",
    "    for i in range(pair_num):\n",
    "        first_pair[i,:] = x_test_nor[a[i*2]]\n",
    "        sec_pair[i,:] = x_test_nor[a[i*2+1]]\n",
    "        if (y_test_nor[a[i*2]]<=y_test_nor[a[i*2+1]]):\n",
    "            label[i] = 1\n",
    "        else:\n",
    "            label[i] = 0\n",
    "    return first_pair, sec_pair, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,t2,y_test = randomtestsample(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = x.shape[1]\n",
    "# Model.\n",
    "h_1 = Dense(32, activation = \"relu\",name = 'h1')\n",
    "h_2 = Dense(16, activation = \"relu\",name = 'h2')\n",
    "h_3 = Dense(8, activation = \"relu\",name = 'h3')\n",
    "s = Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant document score.\n",
    "first_pair = Input(shape = (INPUT_DIM, ), dtype = \"float32\")\n",
    "h_1_first = h_1(first_pair)\n",
    "h_2_first = h_2(h_1_first)\n",
    "h_3_first = h_3(h_2_first)\n",
    "first_score = s(h_3_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irrelevant document score.\n",
    "sec_pair = Input(shape = (INPUT_DIM, ), dtype = \"float32\")\n",
    "h_1_sec = h_1(sec_pair)\n",
    "h_2_sec = h_2(h_1_sec)\n",
    "h_3_sec = h_3(h_2_sec)\n",
    "sec_score = s(h_3_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " h1 (Dense)                     (None, 32)           288         ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " h2 (Dense)                     (None, 16)           528         ['h1[0][0]',                     \n",
      "                                                                  'h1[1][0]']                     \n",
      "                                                                                                  \n",
      " h3 (Dense)                     (None, 8)            136         ['h2[0][0]',                     \n",
      "                                                                  'h2[1][0]']                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            9           ['h3[0][0]',                     \n",
      "                                                                  'h3[1][0]']                     \n",
      "                                                                                                  \n",
      " subtract (Subtract)            (None, 1)            0           ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1)            0           ['subtract[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 961\n",
      "Trainable params: 961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "diff = Subtract()([first_score, sec_score])\n",
    "prob = Activation(\"sigmoid\")(diff)\n",
    "model = Model(inputs = [first_pair, sec_pair], outputs = prob)\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adadelta\", loss = \"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "loss = []\n",
    "val_loss = []\n",
    "acc = []\n",
    "val_acc = []\n",
    "print(\"rs=\"+str(rs)+\" f=\"+str(fnum))\n",
    "for i in range(10):\n",
    "    \n",
    "    print(i)\n",
    "    x1,x2,y = randomsample(x_train)#first_pair, sec_pair, label\n",
    "#    if i ==0:\n",
    "#        weights = model.get_weights()\n",
    "    \n",
    "#    model.set_weights(weights)\n",
    "    history = model.fit([x1, x2], y,validation_split=0.2 ,batch_size = BATCH_SIZE, epochs = NUM_EPOCHS, verbose = 0)\n",
    "    weights = model.get_weights()\n",
    "    loss.extend(history.history['loss'])\n",
    "    val_loss.extend(history.history['val_loss'])\n",
    "    acc.extend(history.history['acc'])\n",
    "    val_acc.extend(history.history['val_acc'])\n",
    "\n",
    "\n",
    "s = model.predict([t1,t2])\n",
    "B = np.where(s > 0.5, 1, 0)\n",
    "err = np.sum(abs(B-y_test))/20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=2)\n",
    "#train = model.fit(x_train_nor, y_train_nor, epochs=300, validation_data=(x_test_nor,y_test_nor), batch_size=256,verbose = 0, callbacks=[early_stopping])\n",
    "# #plot result\n",
    "#l, vl = \"%.2f\" % train.history['loss'][-1], \"%.2f\" % train.history['val_loss'][-1]\n",
    "#plt.title(\"< 7 features >\\n rs = \"+str(rs)+\"\\n loss=\"+str(l)+\"  val_loss=\"+str(vl))\n",
    "#plt.plot(train.history['loss'], label = 'loss' )\n",
    "#plt.plot(train.history['val_loss'], label = 'val_loss' )\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "a, va =  \"%.3f\" % acc[-1],  \"%.3f\" % val_acc[-1]\n",
    "plt.title(\"< \"+str(x.shape[1])+\" features >\\nrs = \"+str(rs)+\"\\n acc=\"+str(a)+\"  val_acc=\"+str(va))\n",
    "plt.plot(acc, label='acc')\n",
    "plt.plot(val_acc, label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
